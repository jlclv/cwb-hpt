{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPTChat: A RAG Chat Application for General and HPT's Internal regulations of ISO 27001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Problem Statement](https://cwbhack.dev/problem-statements/hpt/)\n",
    "Develop a chatbot that takes the role as a Virtual Assistant for all HPT employees to answer the questions related to General and HPT’s Internal regulations of ISO 27001 as well as the evidence of applying the HPT’s regulation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "A multilingual RAG Chat App that assists employees with General and HPT's Internal regulations of ISO 27001 and evidences specific to HPT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "- [VS Code](https://code.visualstudio.com/Download)\n",
    "- [Python](https://www.python.org/)\n",
    "- [Azure AI Search](https://learn.microsoft.com/en-us/azure/search/search-create-service-portal)\n",
    "- [Open AI](https://openai.com/index/openai-api/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Packages & Set-up Environment Variables\n",
    "Run the code below to install packages. Create a `.env` file and insert the following info below: \n",
    "```\n",
    "search_endpoint = \"<YOUR-AZURE-AI-SEARCH-ENDPOINT>\"\n",
    "index_name = \"<NAME-OF-INDEX>\"\n",
    "search_api_key=\"<YOUR-SEARCH-API-KEY>\"\n",
    "openapi_key = \"<YOUR-OPEN-AI-API-KEY>\"\n",
    "\n",
    "\n",
    "translate_endpoint = \"<YOUR-AZURE-TRANSLATION-ENDPOINT>\"\n",
    "translate_api_key = \"<YOUR-AZURE-TRANSLATION-API-KEY>\"\n",
    "translate_region = \"eastus\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Load Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragfunctions import (\n",
    "    get_search_index,\n",
    "    get_embedding,\n",
    "    recursive_chunking,\n",
    "    get_file_stats,\n",
    "    translate_chunk,\n",
    "    ask_data, \n",
    "    )\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "from langchain.document_loaders import PyPDFium2Loader\n",
    "from langchain.vectorstores.azuresearch import AzureSearch\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "import os\n",
    "from dotenv import dotenv_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \".env\"\n",
    "config = dotenv_values(env_name)           \n",
    "\n",
    "# Translate Details \n",
    "translate_endpoint = config[\"translate_endpoint\"]\n",
    "translate_api_key = config[\"translate_api_key\"]\n",
    "translate_region = config[\"translate_region\"]\n",
    "\n",
    "# Azure AI Search Details\n",
    "service_endpoint = config[\"search_endpoint\"]\n",
    "index_name = config[\"index_name\"]\n",
    "search_key = config[\"search_api_key\"]\n",
    "\n",
    "credential = AzureKeyCredential(search_key)\n",
    "\n",
    "# OpenAI Details\n",
    "openapi_key = config[\"openapi_key\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.search.documents.indexes.models._index.SearchIndex at 0x218ab142590>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_client = SearchIndexClient(service_endpoint, credential)\n",
    "index_client.create_index(get_search_index(index_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk, Translate and Upload Documents\n",
    "Data sources: \n",
    "-  HPT’s internal ISO 27K regulations, processes, and evidence of ISO27K implementation. (Provided to Hackathon Participants)\n",
    "- [ISO27k standards](https://www.iso27001security.com/html/iso27000.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### English Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_dir = \"documents/en\"\n",
    "en_pdf_files = [file for file in os.listdir(en_dir) if file.lower().endswith(\".pdf\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Details \n",
    "for filename in en_pdf_files:\n",
    "    fpath = os.path.join(en_dir, filename)\n",
    "    print(f\"{filename} stats:\")\n",
    "    print(get_file_stats(fpath))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_index_client = index_client.get_search_client(index_name)\n",
    "\n",
    "for filename in en_pdf_files:\n",
    "    loader = PyPDFium2Loader(os.path.join(en_dir,filename))\n",
    "    documents = loader.load()\n",
    "    chunks = recursive_chunking(documents)\n",
    "    docs = [\n",
    "    {\n",
    "        \"id\": f\"{filename.rstrip('.pdf')}_{i}\",\n",
    "        \"metadata\": f\"Document:{filename} Page:{chunk.metadata['page']}\",\n",
    "        \"isInternal\": False,\n",
    "        \"en_content\": chunk.page_content,\n",
    "        \"vi_content\": translate_chunk(chunk.page_content.strip('\"'), translate_api_key,translate_region,translate_endpoint),\n",
    "        \"en_content_vector\": get_embedding(chunk.page_content,openapi_key),\n",
    "        \"vi_content_vector\": get_embedding(translate_chunk(chunk.page_content.strip('\"'), translate_api_key,translate_region,translate_endpoint),openapi_key)\n",
    "    }\n",
    "    for i, chunk in enumerate(chunks)\n",
    "    ]\n",
    "\n",
    "    search_index_client.upload_documents(docs)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vietnamese Documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi_dir = \"documents/vi\"\n",
    "vi_pdf_files = [file for file in os.listdir(vi_dir) if file.lower().endswith(\".pdf\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Details \n",
    "for filename in vi_pdf_files:\n",
    "    fpath = os.path.join(vi_dir, filename)\n",
    "    print(f\"{filename} stats:\")\n",
    "    print(get_file_stats(fpath))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_index_client = index_client.get_search_client(index_name)\n",
    "\n",
    "for filename in vi_pdf_files:\n",
    "    loader = PyPDFium2Loader(os.path.join(vi_dir,filename))\n",
    "    documents = loader.load()\n",
    "    chunks = recursive_chunking(documents)\n",
    "    docs = [\n",
    "    {\n",
    "        \"id\": f\"{filename.rstrip('.pdf')}_{i}\",\n",
    "        \"metadata\": f\"Document:{filename} Page:{chunk.metadata['page']}\",\n",
    "        \"isInternal\": True,\n",
    "        \"en_content\": translate_chunk(chunk.page_content.strip('\"'), translate_api_key,translate_region,translate_endpoint,langFrom=\"vi\",langTo=\"en\"),\n",
    "        \"vi_content\": chunk.page_content,\n",
    "        \"en_content_vector\": get_embedding(translate_chunk(chunk.page_content.strip('\"'), translate_api_key,translate_region,translate_endpoint,langFrom=\"vi\",langTo=\"en\"),openapi_key),\n",
    "        \"vi_content_vector\": get_embedding(chunk.page_content,openapi_key),\n",
    "    }\n",
    "    for i, chunk in enumerate(chunks)\n",
    "    ]\n",
    "\n",
    "    search_index_client.upload_documents(docs)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat with Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ask_data(\"What is ISO27k\", \"en\", service_endpoint, index_name, search_key, openapi_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradio WebApp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import time\n",
    "\n",
    "api_key = openapi_key  # Replace with your key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "def predict(message, history, system_prompt, tokens, checkbox):\n",
    "    history_openai_format = []\n",
    "    for human, assistant in history:\n",
    "        history_openai_format.append({\"role\": \"user\", \"content\": human })\n",
    "        history_openai_format.append({\"role\": \"assistant\", \"content\":assistant})\n",
    "    history_openai_format.append({\"role\": \"user\", \"content\": message})\n",
    "  \n",
    "    response = client.chat.completions.create(model='gpt-3.5-turbo',\n",
    "    messages= history_openai_format,\n",
    "    temperature=1.0,\n",
    "    stream=True)\n",
    "\n",
    "    partial_message = \"\"\n",
    "    for chunk in response:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "              partial_message = partial_message + chunk.choices[0].delta.content\n",
    "              yield partial_message\n",
    "    \n",
    "def context():\n",
    "    return \"\"\"\n",
    "    You are an assistant that helps company employees with their ISO27K questions, and questions about Internal regulations of ISO 27001. Be detailed and complete with your answers.\n",
    "    Answer ONLY with the information above. \n",
    "    If there isn't enough information below, say you don't know. \n",
    "    Do not make up your own answers. \n",
    "    If asking a clarifying question to the user would help, ask the question.\n",
    "    If the question is not in English, answer in the language used in the question.\n",
    "    Each source contains a metadata that has the name followed by colon and the actual information, \n",
    "    always include the metadata document for each fact you use in the response. \n",
    "    Use square brackets to reference the metadata, for example [info1.pdf Page:0]. \n",
    "    Don't combine metadata, list each metadata separately, for example [info1.pdf Page:1][info2.pdf Page:2].\n",
    "\"\"\"\n",
    "\n",
    "def get_embedding(text, key, model=\"text-embedding-ada-002\"):\n",
    "   client = OpenAI(api_key=key)\n",
    "   \n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "def chat_data(message, history, system_prompt, radio, isInternal):\n",
    "    language = \"en\"\n",
    "    if radio is not None:\n",
    "        language = radio \n",
    "\n",
    "    search_client = SearchClient(service_endpoint, index_name, AzureKeyCredential(search_key))\n",
    "    vector_query = VectorizedQuery(vector=get_embedding(message, openapi_key), k_nearest_neighbors=3, fields=f\"{language}_content_vector\")\n",
    "    filter = f\"{'isInternal eq true' if isInternal else ''}\"\n",
    "\n",
    "    results = search_client.search(\n",
    "            message,\n",
    "            vector_queries=[vector_query],\n",
    "            top=3,\n",
    "            filter=filter,\n",
    "            query_type=\"semantic\",\n",
    "            semantic_configuration_name=\"hpt-semantic-config\",\n",
    "            select=[\"metadata\", f\"{language}_content\"],\n",
    "        )\n",
    "\n",
    "    fulltext_list = []\n",
    "\n",
    "    for result in results:\n",
    "        reference = result[f\"{language}_content\"] + \" \"\n",
    "        reference += result[\"metadata\"]\n",
    "        fulltext_list.append(reference)\n",
    "\n",
    "    fulltext = \"\".join(fulltext_list)\n",
    "\n",
    "    client = OpenAI(api_key=openapi_key)\n",
    "\n",
    "    history_openai_format = []\n",
    "    for human, assistant in history:\n",
    "        history_openai_format.append({\"role\": \"user\", \"content\": human })\n",
    "        history_openai_format.append({\"role\": \"assistant\", \"content\":assistant})\n",
    "    history_openai_format.append({\"role\": \"user\", \"content\": fulltext})\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "    model= \"gpt-3.5-turbo-0125\",\n",
    "    stream=True,\n",
    "    messages=history_openai_format\n",
    "    )\n",
    "\n",
    "    partial_message = \"\"\n",
    "    for chunk in completion:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "              partial_message = partial_message + chunk.choices[0].delta.content\n",
    "              yield partial_message\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    system_prompt = gr.Textbox(context(), label=\"System Prompt\")\n",
    "    radio = gr.Radio([\"en\", \"vi\"], label=\"Search Index\", info=\"Select Index Language\")\n",
    "    slider = gr.Slider(10, 100, render=False)\n",
    "    checkbox = gr.Checkbox(label=\"Internal\", info=\"Limit to Internal Documents?\")\n",
    "\n",
    "    gr.ChatInterface(\n",
    "        chat_data, additional_inputs=[system_prompt, radio, checkbox]\n",
    "    )\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cwb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
